{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# KNN算法\n",
    "\n",
    "\n",
    "kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 \n",
    "\n",
    "三要素：k值选择、距离矢量、分类决策规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### k值选择\n",
    "\n",
    "- 应用中，k值一般取一个较小的数值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "如果k=3，在已有的分类样本上，这时来了一个新样本，那么这个新样本所属的类就是在最临近的三个样本中占较大比重的那一类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 距离矢量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 特征空间中两个实例点的距离是两个实例点相似程度的反映\n",
    "- K近邻模型的特征空间的距离一般为欧式距离，也可以是$L_p$距离：\n",
    "\n",
    "\n",
    "$L_p(\\vec{x_i},\\vec{x_j}) = (\\sum_{l=1}^n|x_i^{(l)}-x_i^{(l)}|^p)^{1/p}$   \n",
    "\n",
    "\n",
    "$\\vec{x_i},\\vec{x_j} \\in \\chi = \\mathbb{R}^n $   \n",
    "$\\vec{x_i} = (x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^T$    \n",
    "$\\vec{x_j} = (x_j^{(1)},x_j^{(2)},...,x_j^{(n)})^T$   \n",
    "$p \\ge 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 当p=2时，为欧式距离：$L_2(\\vec{x_i},\\vec{x_j}) = (\\sum_{l=1}^n|x_i^{(l)}-x_i^{(l)}|^2)^{1/2}$ \n",
    "- 当p=1时，为曼哈顿距离：$L_1(\\vec{x_i},\\vec{x_j}) = \\sum_{l=1}^n|x_i^{(l)}-x_i^{(l)}|$ \n",
    "- 当p=$\\infty$无穷大时，为各维度距离中的最大值：$L_\\infty(\\vec{x_i},\\vec{x_j}) = max_l|x_i^{(l)}-x_i^{(l)}|$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 分类决策规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 误分类率\n",
    "\n",
    "$\\frac{1}{k}\\sum_{\\vec{x_i}\\in N_k(\\vec{x})}I(y_i\\ne c_j)=1-\\frac{1}{k}\\sum_{\\vec{x_i}\\in N_k(\\vec{x})}I(y_i = c_j)$\n",
    "\n",
    "$c_j$表示类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 多数表决\n",
    "\n",
    "$y = c_j = arg max_{c_j} \\sum_{\\overline{x_i}\\in N_k(\\overline{x})}I(y_i\\ne c_j), i = 1,2,3,...,N; j = 1,2,3,...,K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** KNN算法经典实例 **\n",
    "\n",
    "[KNN算法经典实例](KNN算法经典实例.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
