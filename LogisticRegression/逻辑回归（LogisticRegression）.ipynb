{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 线性回归\n",
    "\n",
    "- 基本形式\n",
    "- 误差函数\n",
    "- 使误差函数最小\n",
    "- 广义线性模型\n",
    "- 对数几率回归\n",
    "- 线性判别分析\n",
    "- 对分类学习\n",
    "- 类别不平衡的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 基本形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ f(x_i) =wx_i + b , 使得f(x_i) = y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 误差函数\n",
    "\n",
    "为了衡量预测值和真实值之间的误差大小，构造误差函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$E(w,b) = \\sum_{i=1}^{m}(f(x_i) - y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 使误差函数值最小\n",
    "\n",
    "- 通过求导获得\n",
    "- 通过最小二乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** 求导得出w，b **\n",
    "\n",
    "$$w = \\frac{\\sum_{i=1}^{m}y_i(x_i-\\overline{x})}{\\sum_{i=1}^{m}x_i^2 - \\frac{1}{m}(\\sum_{i}^{m}x_i)^2}$$   \n",
    "$$b = \\frac{1}{m} \\sum_{i=1}^{m}(y_i - wx_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** 最小二乘求得w **\n",
    "\n",
    "$$ \\hat{w}^* = (X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广义线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性模型简写为：\n",
    "\n",
    "$$y = w^Tx + b$$\n",
    "\n",
    "可否另模型预测值逼近y的衍生物呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如假如我们人为示例所对应的输出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目标：\n",
    "\n",
    "$$lny = w^Tx + b $$\n",
    "\n",
    "这就是“对数线性回归”，就是试图让$e^{w^Tx + b}$逼近y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更一般的，考虑单调可微函数$g(\\cdot)$，令：\n",
    "\n",
    "$$y = g_{-1}(w^Tx + b)$$\n",
    "\n",
    "这就是“广义相对模型”，$g(\\cdot)$函数成为“联系函数”，对数线性回归模型就是广义线性模型在$g(\\cdot) = ln(\\cdot)$时的特例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 对数几率回归 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 逻辑回归（Logistic Regression）\n",
    "\n",
    "Regression问题的常规步骤为：\n",
    "- 寻找h函数（即hypothesis）；\n",
    "- 构造J函数（损失函数）；\n",
    "- 想办法使得J函数最小并求得回归参数（θ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 构造预测函数h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "函数形式为：\n",
    "\n",
    "$h_\\theta (x) = g(\\theta^T x) = \\frac{1}{1+e^{-\\theta^T x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "函数$h_\\theta(x)$的值有特殊的含义，它表示结果取1的概率，因此对于输入x分类结果为类别1和类别0的概率分别为：\n",
    "\n",
    "$P(y = 1|x;\\theta) = h_\\theta(x) $   \n",
    "$P(y = 0|x;\\theta) = 1- h_\\theta(x) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 构造损失函数J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "将上面二式综合起来\n",
    "\n",
    "$P(y|x;\\theta) = (h_\\theta(x))^y(1- h_\\theta(x))^{1-y} $   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "取似然函数为：\n",
    "\n",
    "$L(\\theta) = \\Pi_{i=1}^{m}P(y_i|x_i;\\theta) = \\Pi_{i=1}^{m}(h_\\theta(x_i))^{y_i}(1- h_\\theta(x_i))^{1-y_i}$\n",
    "\n",
    "对数似然函数为：\n",
    "\n",
    "$l(\\theta) = logL(\\theta) = \\sum_{i=1}^{m}(y_ih_\\theta(x_i)+(1-y_i)(1- h_\\theta(x_i)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "最大似然估计就是求使$l(\\theta)$取最大值时的θ，其实这里可以使用梯度上升法求解，求得的θ就是要求的最佳参数。\n",
    "\n",
    "$J(\\theta) = -\\frac{1}{m}l(\\theta)$\n",
    "\n",
    "因为乘了一个负的系数-1/m，所以取$J(\\theta)$最小值时的θ为要求的最佳参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 梯度下降法求的最小值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\theta$更新过程:\n",
    "\n",
    "$\\theta_j:=\\theta_j - \\alpha \\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta (x_i) - y_i)x_i^j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** 逻辑回归（Logistic Regression）经典实例 **\n",
    "\n",
    "[逻辑回归（Logistic Regression）经典实例](逻辑回归（Logistic Regression）经典实例.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
