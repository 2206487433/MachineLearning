{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 逻辑回归（Logistic Regression）\n",
    "\n",
    "Regression问题的常规步骤为：\n",
    "- 寻找h函数（即hypothesis）；\n",
    "- 构造J函数（损失函数）；\n",
    "- 想办法使得J函数最小并求得回归参数（θ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 构造预测函数h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "函数形式为：\n",
    "\n",
    "$h_\\theta (x) = g(\\theta^T x) = \\frac{1}{1+e^{-\\theta^T x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "函数$h_\\theta(x)$的值有特殊的含义，它表示结果取1的概率，因此对于输入x分类结果为类别1和类别0的概率分别为：\n",
    "\n",
    "$P(y = 1|x;\\theta) = h_\\theta(x) $   \n",
    "$P(y = 0|x;\\theta) = 1- h_\\theta(x) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 构造损失函数J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "将上面二式综合起来\n",
    "\n",
    "$P(y|x;\\theta) = (h_\\theta(x))^y(1- h_\\theta(x))^{1-y} $   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "取似然函数为：\n",
    "\n",
    "$L(\\theta) = \\Pi_{i=1}^{m}P(y_i|x_i;\\theta) = \\Pi_{i=1}^{m}(h_\\theta(x_i))^{y_i}(1- h_\\theta(x_i))^{1-y_i}$\n",
    "\n",
    "对数似然函数为：\n",
    "\n",
    "$l(\\theta) = logL(\\theta) = \\sum_{i=1}^{m}(y_ih_\\theta(x_i)+(1-y_i)(1- h_\\theta(x_i)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "最大似然估计就是求使$l(\\theta)$取最大值时的θ，其实这里可以使用梯度上升法求解，求得的θ就是要求的最佳参数。\n",
    "\n",
    "$J(\\theta) = -\\frac{1}{m}l(\\theta)$\n",
    "\n",
    "因为乘了一个负的系数-1/m，所以取$J(\\theta)$最小值时的θ为要求的最佳参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 梯度下降法求的最小值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\theta$更新过程:\n",
    "\n",
    "$\\theta_j:=\\theta_j - \\alpha \\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta (x_i) - y_i)x_i^j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** 逻辑回归（Logistic Regression）经典实例 **\n",
    "\n",
    "[逻辑回归（Logistic Regression）经典实例](逻辑回归（Logistic Regression）经典实例.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
