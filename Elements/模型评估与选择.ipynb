{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估与选择\n",
    "\n",
    "- 经验误差与过拟合\n",
    "- 评估方法\n",
    "- 性能度量\n",
    "- 比较检验\n",
    "- 偏差与方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 经验误差与过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 误差率：分类错误的样本数占样本总数的比例\n",
    "- 精度：1 - 错误率\n",
    "- 误差：学习器的实际预测输出与样本的真实输出之间的差异\n",
    "- 过拟合：训练样本学的太好，就是把训练样本的所有特征当作了所有样本的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 留出法 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "留出法比较简单，就是把数据集进行划分，划分为两个互斥的集合，一个作为训练集，一个作为测试集，至于怎么分，采用什么样的采样方法，可以自己决定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 交叉验证法 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首先把数据集划分为k个大小相同的互斥子集\n",
    "- 每次用k-1个子集作为训练集，一个子集作为测试集\n",
    "- 交叉使用这k个子集作为测试集，从而进行k次训练和测试，最终返回这k个结果的均值\n",
    "- 这就是k折交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 自助法 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自助法和交叉验证法有点相似，不同的是，两个划分数据的方式不同，自助法方法如下：\n",
    "\n",
    "- 首先首先从m个样本的数据集D中，可放回的重复抽样m次，得到一个有m个样本的数据集$D_i$\n",
    "- 这样的抽样方式在$D_i$肯定有重复的数据,有一部分数据肯定没有抽到，没有抽到的概率为$(1-\\frac{1}{m})^m$\n",
    "- 用含有m个样本的数据集$D_i$作为训练集，剩下的没有抽到的作为测试集\n",
    "- 将这样的动作重复多次就可以训练出多个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 自助法在数据集较小、难以有效划分训练/测试集时很有用，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法很有效   \n",
    "> 自助法产生的数据集改变了初始数据集的分布，这会引入估计误差，因此数据量足够时，留出法和交叉验证法更常用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 调参与最终模型 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 大多数的学习算法都有参数需要设定，参数配置不同学习的模型的性能往往有显著差别\n",
    "- 但是在调参的时候要注意设置步长，否则在实数范围内，对每种参数配置训练出模型来是不可能的\n",
    "- 调参是一件困难的工程，比如算法有3个参数，每个参数考虑5个候选参数，这就有$5^3 = 125$个模型\n",
    "- 模型选择时要把训练数据分成训练集和验证集，选择最好的模型，然后用所有的训练数据重新训练模型，最后再用测试集测试结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举个例子，$y$为真是值，$f(x)$为预测结果\n",
    "\n",
    "回归任务最常用的性能度量时“均方误差“：\n",
    "\n",
    "$$E(f:D) = \\frac{1}{m} \\sum_{i=1}^{m}(f(x)-y)^2$$\n",
    "\n",
    "更一般的，对于数据分布$D$和概率密度函数$p(\\cdot)$，均方误差：\n",
    "\n",
    "$$E(f:D) = \\int_{x\\backsim D} p(x)(f(x)-y)^2 dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 错误率与精度 **\n",
    "\n",
    "分类任务，最常用的性能测量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "错误率：\n",
    "\n",
    "$$E(f:D) = \\frac{1}{m} \\sum_{i=1}^{m} \\amalg (f(x)\\ne y_i)$$\n",
    "\n",
    "精度：\n",
    "\n",
    "$$acc(f:D) = \\frac{1}{m} \\sum_{i=1}^{m} \\amalg (f(x) = y_i) = 1 - E(f:D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更一般的，对于数据分布$D$和概率密度函数$p(\\cdot)$，错误率和精度：\n",
    "\n",
    "$$E(f:D) = \\int_{x\\backsim D} p(x) \\amalg (f(x)\\ne y_i) dx$$\n",
    "\n",
    "$$acc(f:D) = \\int_{x\\backsim D} p(x) \\amalg (f(x) = y_i) dx = 1 - E(f:D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 查准率、查全率和F1 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举一个医院的例子，错误率就是一个医生对病人的误判率，但是并没有说时把健康的人误判为病人还是把病人误判为健康的人，这是两种完全不同的结果，所以错误率这时候就不够用了。\n",
    "\n",
    "还有就是信息检索时，我们经常关心”检索出来的信息有多少比例是用户感兴趣的“ ”用户感兴趣的信息中有多少被检索出来了“，这两个就分别对应了“查准率”和“查全率”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分类问题，用一个分类结果混淆矩阵说明：\n",
    "\n",
    "|真实情况|预测结果|\n",
    "|:----:|:----:|:-----:|\n",
    "||正例|反例|\n",
    "|正例|TP(真正例)|FN(假反例)|\n",
    "|反例|FP(假正例)|TN(真反例)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查准率： $P = \\frac{TP}{TP + FP}$   \n",
    "查全率： $R = \\frac{TP}{TP + FN}$    \n",
    "查准率和查全率的不同偏好： $F_\\beta = \\frac{(1 + \\beta^2) \\times P \\times R}{(\\beta^2 \\times P) + R}$  \n",
    "\n",
    "> 其中$\\beta > 0$度量了查全率对查准率的相对重要性，$\\beta = 1$是标准的$F_1$, $\\beta > 1$时查全率有更大的影响，$\\beta < 1$时查准率有更大的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ROC和AUC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC曲线的横纵坐标分别是：\n",
    "\n",
    "横坐标为假正例率：$FPR = \\frac{FP}{FP + TN}$     \n",
    "纵坐标为真正例率：$TPR = \\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若一个学习器的ROC曲线被另一个学习器的ROC曲线包裹，则后者优于前者，如果两条曲线发生重合，则使用ROC曲线下的面积，即AUC\n",
    "\n",
    "$$AUC = \\frac{1}{2} \\sum_{i=1}^{m-1}(x_{i+1} - x_i)(y_i + y_{i+1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比较检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 偏差与方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 泛化误差是指在新样本上的误差\n",
    "- 泛化误差等于偏差、方差与噪声之和\n",
    "    - 偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力\n",
    "    - 方差度量了同样大小的训练集的变动所导致的学习性能的变化，即数据扰动所造成的影响\n",
    "    - 噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
